# Extension .env (root directory)
# Point to your LLM relay server
LLM_BASE_URL=http://localhost:8787

# Server .env (server/ directory)  
# Your LLM API credentials (keep these server-side only)
LLM_API_KEY=your_gemini_api_key_here
LLM_BASE_URL=https://generativelanguage.googleapis.com/v1beta #i.e gemini
LLM_MODEL=gemini-2.5-flash #i.e gemini model for planning/questions
LLM_FINAL_MODEL=gemini-2.5-pro #i.e gemini model for final prompt (best accuracy)
PORT=8787
